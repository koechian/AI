{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task / Question\n",
    "1. Load the given dataset into a pandas data frame.\n",
    "2. Develop a Multi-Layer Perceptron (MLP) model to regress the target variable y.\n",
    "3. Evaluate the model using appropriate metrics.\n",
    "4. Your MLP model should have at least 3 hidden layers and 1 output layer. You can use any number of neurons in each layer however, you should be able to justify your choice.\n",
    "5. You can use any activation function in the hidden layers however, you should be able to justify your choice. Remember this is a regression problem hence referring to the equation *y = mx + c* might help.\n",
    "\n",
    "#### Items to consider:\n",
    "1. Dataset has 200 features and 1 target variable. Not all features are relevant for the target variable hence apply feature selection techniques to select the most relevant features.\n",
    "2. Use appropriate data pre-processing techniques to prepare the data for the model.\n",
    "3. You can use:\n",
    "    - Pytorch\n",
    "    - Tensorflow v2\n",
    "    - Scikit-learn (MLPRegressor)\n",
    "    - Custom implementation of MLP\n",
    "\n",
    "    <br><br>\n",
    "\n",
    "\n",
    "\n",
    "### Deliverables:\n",
    "1. **Jupyter notebook** with the code and results included\n",
    "    - name the notebook using the format: **A-111111.ipynb**, where A is your group and 111111 is your student number. Any other fill names will lead to an automatic 0 mark.\n",
    "    - Do not attempt to submit your file via email. If E-Learning fails on the deadline, an alternative submission method will be provided; to avoid this chaos simply  do your work before the deadline.\n",
    "    - Any slight hint of plagiarism will lead to an automatic 0 mark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X192</th>\n",
       "      <th>X193</th>\n",
       "      <th>X194</th>\n",
       "      <th>X195</th>\n",
       "      <th>X196</th>\n",
       "      <th>X197</th>\n",
       "      <th>X198</th>\n",
       "      <th>X199</th>\n",
       "      <th>X200</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>-0.214494</td>\n",
       "      <td>-0.526423</td>\n",
       "      <td>1.737889</td>\n",
       "      <td>0.363136</td>\n",
       "      <td>-0.833223</td>\n",
       "      <td>1.463178</td>\n",
       "      <td>0.867419</td>\n",
       "      <td>0.667468</td>\n",
       "      <td>0.163676</td>\n",
       "      <td>-0.537552</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.545196</td>\n",
       "      <td>0.211031</td>\n",
       "      <td>0.191622</td>\n",
       "      <td>-1.335153</td>\n",
       "      <td>-0.228597</td>\n",
       "      <td>0.853606</td>\n",
       "      <td>-1.261840</td>\n",
       "      <td>0.478774</td>\n",
       "      <td>1.584665</td>\n",
       "      <td>231.992020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>0.607274</td>\n",
       "      <td>-0.210262</td>\n",
       "      <td>-1.533856</td>\n",
       "      <td>-1.852737</td>\n",
       "      <td>-0.438336</td>\n",
       "      <td>0.531767</td>\n",
       "      <td>-0.199320</td>\n",
       "      <td>-1.088554</td>\n",
       "      <td>-0.097510</td>\n",
       "      <td>0.378743</td>\n",
       "      <td>...</td>\n",
       "      <td>1.009495</td>\n",
       "      <td>0.206452</td>\n",
       "      <td>-0.724171</td>\n",
       "      <td>0.497313</td>\n",
       "      <td>0.057857</td>\n",
       "      <td>-1.274429</td>\n",
       "      <td>0.003254</td>\n",
       "      <td>0.873530</td>\n",
       "      <td>1.182927</td>\n",
       "      <td>14.053699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>0.911011</td>\n",
       "      <td>0.165072</td>\n",
       "      <td>0.379275</td>\n",
       "      <td>0.503359</td>\n",
       "      <td>-0.448846</td>\n",
       "      <td>-0.781213</td>\n",
       "      <td>-0.976645</td>\n",
       "      <td>-1.695327</td>\n",
       "      <td>-0.191790</td>\n",
       "      <td>0.504117</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.897659</td>\n",
       "      <td>-1.747071</td>\n",
       "      <td>0.663051</td>\n",
       "      <td>0.313583</td>\n",
       "      <td>-2.058141</td>\n",
       "      <td>0.661069</td>\n",
       "      <td>1.463502</td>\n",
       "      <td>-0.873551</td>\n",
       "      <td>-0.935928</td>\n",
       "      <td>-369.678159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0.097610</td>\n",
       "      <td>-0.243182</td>\n",
       "      <td>-0.598185</td>\n",
       "      <td>1.588426</td>\n",
       "      <td>-1.083978</td>\n",
       "      <td>-0.106720</td>\n",
       "      <td>0.549441</td>\n",
       "      <td>0.123725</td>\n",
       "      <td>1.198469</td>\n",
       "      <td>0.483194</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082820</td>\n",
       "      <td>-0.504300</td>\n",
       "      <td>0.002888</td>\n",
       "      <td>0.522576</td>\n",
       "      <td>-0.812748</td>\n",
       "      <td>1.408881</td>\n",
       "      <td>-0.391760</td>\n",
       "      <td>1.720578</td>\n",
       "      <td>1.060746</td>\n",
       "      <td>-139.980854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>0.441370</td>\n",
       "      <td>-0.786063</td>\n",
       "      <td>-0.732875</td>\n",
       "      <td>0.866461</td>\n",
       "      <td>-0.494958</td>\n",
       "      <td>-0.567279</td>\n",
       "      <td>-0.347578</td>\n",
       "      <td>-0.787476</td>\n",
       "      <td>-2.162638</td>\n",
       "      <td>-0.563442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987795</td>\n",
       "      <td>0.244834</td>\n",
       "      <td>0.978485</td>\n",
       "      <td>0.894197</td>\n",
       "      <td>-0.306384</td>\n",
       "      <td>0.073213</td>\n",
       "      <td>-0.952186</td>\n",
       "      <td>0.577228</td>\n",
       "      <td>-0.748844</td>\n",
       "      <td>-186.034770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>-0.013216</td>\n",
       "      <td>-0.424919</td>\n",
       "      <td>-0.681891</td>\n",
       "      <td>0.174947</td>\n",
       "      <td>0.600912</td>\n",
       "      <td>0.436029</td>\n",
       "      <td>0.836297</td>\n",
       "      <td>0.412544</td>\n",
       "      <td>-1.062567</td>\n",
       "      <td>-0.281578</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.122084</td>\n",
       "      <td>0.992812</td>\n",
       "      <td>-0.111512</td>\n",
       "      <td>0.385950</td>\n",
       "      <td>0.192170</td>\n",
       "      <td>-0.710030</td>\n",
       "      <td>0.538972</td>\n",
       "      <td>-0.197348</td>\n",
       "      <td>-0.217693</td>\n",
       "      <td>292.190962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>0.602242</td>\n",
       "      <td>0.398334</td>\n",
       "      <td>-0.829134</td>\n",
       "      <td>-1.100999</td>\n",
       "      <td>1.990874</td>\n",
       "      <td>-0.618697</td>\n",
       "      <td>-1.130042</td>\n",
       "      <td>-1.271964</td>\n",
       "      <td>-0.601665</td>\n",
       "      <td>-1.029683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.429916</td>\n",
       "      <td>1.580374</td>\n",
       "      <td>0.431153</td>\n",
       "      <td>-0.395067</td>\n",
       "      <td>-1.620270</td>\n",
       "      <td>1.223682</td>\n",
       "      <td>0.773566</td>\n",
       "      <td>-0.487254</td>\n",
       "      <td>0.317940</td>\n",
       "      <td>-229.696688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>0.531438</td>\n",
       "      <td>-0.483741</td>\n",
       "      <td>0.986426</td>\n",
       "      <td>1.640005</td>\n",
       "      <td>1.162261</td>\n",
       "      <td>1.285156</td>\n",
       "      <td>-0.707655</td>\n",
       "      <td>0.271801</td>\n",
       "      <td>0.818334</td>\n",
       "      <td>-0.077160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819192</td>\n",
       "      <td>-1.924285</td>\n",
       "      <td>-0.167290</td>\n",
       "      <td>0.188999</td>\n",
       "      <td>2.319434</td>\n",
       "      <td>1.030900</td>\n",
       "      <td>0.236533</td>\n",
       "      <td>-0.460329</td>\n",
       "      <td>-0.661208</td>\n",
       "      <td>-65.883302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0.259501</td>\n",
       "      <td>0.580974</td>\n",
       "      <td>1.186829</td>\n",
       "      <td>-0.747786</td>\n",
       "      <td>0.042188</td>\n",
       "      <td>0.672187</td>\n",
       "      <td>-0.172325</td>\n",
       "      <td>0.703192</td>\n",
       "      <td>1.142885</td>\n",
       "      <td>1.152579</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162724</td>\n",
       "      <td>-0.802573</td>\n",
       "      <td>-0.625687</td>\n",
       "      <td>-0.831675</td>\n",
       "      <td>1.418508</td>\n",
       "      <td>-1.469225</td>\n",
       "      <td>-1.108635</td>\n",
       "      <td>0.955053</td>\n",
       "      <td>0.159341</td>\n",
       "      <td>-151.175024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.279270</td>\n",
       "      <td>-1.000540</td>\n",
       "      <td>-1.041783</td>\n",
       "      <td>0.124758</td>\n",
       "      <td>0.272724</td>\n",
       "      <td>0.207792</td>\n",
       "      <td>-1.085783</td>\n",
       "      <td>0.386609</td>\n",
       "      <td>0.988844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969003</td>\n",
       "      <td>-0.954743</td>\n",
       "      <td>0.589940</td>\n",
       "      <td>-1.606696</td>\n",
       "      <td>0.262953</td>\n",
       "      <td>0.108388</td>\n",
       "      <td>-0.228276</td>\n",
       "      <td>0.055086</td>\n",
       "      <td>1.659464</td>\n",
       "      <td>48.814088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X1        X2        X3        X4        X5        X6        X7  \\\n",
       "960  -0.214494 -0.526423  1.737889  0.363136 -0.833223  1.463178  0.867419   \n",
       "698   0.607274 -0.210262 -1.533856 -1.852737 -0.438336  0.531767 -0.199320   \n",
       "697   0.911011  0.165072  0.379275  0.503359 -0.448846 -0.781213 -0.976645   \n",
       "338   0.097610 -0.243182 -0.598185  1.588426 -1.083978 -0.106720  0.549441   \n",
       "1233  0.441370 -0.786063 -0.732875  0.866461 -0.494958 -0.567279 -0.347578   \n",
       "1056 -0.013216 -0.424919 -0.681891  0.174947  0.600912  0.436029  0.836297   \n",
       "1173  0.602242  0.398334 -0.829134 -1.100999  1.990874 -0.618697 -1.130042   \n",
       "723   0.531438 -0.483741  0.986426  1.640005  1.162261  1.285156 -0.707655   \n",
       "373   0.259501  0.580974  1.186829 -0.747786  0.042188  0.672187 -0.172325   \n",
       "685        NaN  0.279270 -1.000540 -1.041783  0.124758  0.272724  0.207792   \n",
       "\n",
       "            X8        X9       X10  ...      X192      X193      X194  \\\n",
       "960   0.667468  0.163676 -0.537552  ... -0.545196  0.211031  0.191622   \n",
       "698  -1.088554 -0.097510  0.378743  ...  1.009495  0.206452 -0.724171   \n",
       "697  -1.695327 -0.191790  0.504117  ... -1.897659 -1.747071  0.663051   \n",
       "338   0.123725  1.198469  0.483194  ... -0.082820 -0.504300  0.002888   \n",
       "1233 -0.787476 -2.162638 -0.563442  ...  0.987795  0.244834  0.978485   \n",
       "1056  0.412544 -1.062567 -0.281578  ... -0.122084  0.992812 -0.111512   \n",
       "1173 -1.271964 -0.601665 -1.029683  ... -0.429916  1.580374  0.431153   \n",
       "723   0.271801  0.818334 -0.077160  ...  0.819192 -1.924285 -0.167290   \n",
       "373   0.703192  1.142885  1.152579  ... -0.162724 -0.802573 -0.625687   \n",
       "685  -1.085783  0.386609  0.988844  ...  0.969003 -0.954743  0.589940   \n",
       "\n",
       "          X195      X196      X197      X198      X199      X200           y  \n",
       "960  -1.335153 -0.228597  0.853606 -1.261840  0.478774  1.584665  231.992020  \n",
       "698   0.497313  0.057857 -1.274429  0.003254  0.873530  1.182927   14.053699  \n",
       "697   0.313583 -2.058141  0.661069  1.463502 -0.873551 -0.935928 -369.678159  \n",
       "338   0.522576 -0.812748  1.408881 -0.391760  1.720578  1.060746 -139.980854  \n",
       "1233  0.894197 -0.306384  0.073213 -0.952186  0.577228 -0.748844 -186.034770  \n",
       "1056  0.385950  0.192170 -0.710030  0.538972 -0.197348 -0.217693  292.190962  \n",
       "1173 -0.395067 -1.620270  1.223682  0.773566 -0.487254  0.317940 -229.696688  \n",
       "723   0.188999  2.319434  1.030900  0.236533 -0.460329 -0.661208  -65.883302  \n",
       "373  -0.831675  1.418508 -1.469225 -1.108635  0.955053  0.159341 -151.175024  \n",
       "685  -1.606696  0.262953  0.108388 -0.228276  0.055086  1.659464   48.814088  \n",
       "\n",
       "[10 rows x 201 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X192</th>\n",
       "      <th>X193</th>\n",
       "      <th>X194</th>\n",
       "      <th>X195</th>\n",
       "      <th>X196</th>\n",
       "      <th>X197</th>\n",
       "      <th>X198</th>\n",
       "      <th>X199</th>\n",
       "      <th>X200</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>0.731869</td>\n",
       "      <td>-1.096852</td>\n",
       "      <td>0.198551</td>\n",
       "      <td>1.108424</td>\n",
       "      <td>-0.600812</td>\n",
       "      <td>0.722716</td>\n",
       "      <td>-0.332837</td>\n",
       "      <td>-0.436027</td>\n",
       "      <td>-0.812805</td>\n",
       "      <td>-0.391231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109321</td>\n",
       "      <td>-0.827960</td>\n",
       "      <td>0.030530</td>\n",
       "      <td>-0.268029</td>\n",
       "      <td>1.521622</td>\n",
       "      <td>0.364885</td>\n",
       "      <td>0.558242</td>\n",
       "      <td>0.860434</td>\n",
       "      <td>0.513657</td>\n",
       "      <td>-142.554141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1.041167</td>\n",
       "      <td>-1.356877</td>\n",
       "      <td>1.170723</td>\n",
       "      <td>-0.192536</td>\n",
       "      <td>-0.010444</td>\n",
       "      <td>-1.059061</td>\n",
       "      <td>-0.552038</td>\n",
       "      <td>-0.556104</td>\n",
       "      <td>1.435185</td>\n",
       "      <td>-0.376649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.610066</td>\n",
       "      <td>-0.499520</td>\n",
       "      <td>-1.536939</td>\n",
       "      <td>-1.110738</td>\n",
       "      <td>0.663073</td>\n",
       "      <td>-1.174878</td>\n",
       "      <td>0.016668</td>\n",
       "      <td>0.144020</td>\n",
       "      <td>0.429925</td>\n",
       "      <td>230.218687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>-0.142184</td>\n",
       "      <td>0.677312</td>\n",
       "      <td>1.673367</td>\n",
       "      <td>-1.631981</td>\n",
       "      <td>0.896933</td>\n",
       "      <td>-0.736006</td>\n",
       "      <td>0.955523</td>\n",
       "      <td>0.473728</td>\n",
       "      <td>0.399525</td>\n",
       "      <td>2.004731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172301</td>\n",
       "      <td>0.444955</td>\n",
       "      <td>0.052372</td>\n",
       "      <td>0.567104</td>\n",
       "      <td>-0.477640</td>\n",
       "      <td>1.033732</td>\n",
       "      <td>-0.714290</td>\n",
       "      <td>-0.787753</td>\n",
       "      <td>-1.367362</td>\n",
       "      <td>-66.363159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.515979</td>\n",
       "      <td>0.258770</td>\n",
       "      <td>-0.232026</td>\n",
       "      <td>-0.110359</td>\n",
       "      <td>-0.821613</td>\n",
       "      <td>1.278475</td>\n",
       "      <td>-0.550324</td>\n",
       "      <td>0.700158</td>\n",
       "      <td>1.495035</td>\n",
       "      <td>-0.447937</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.255225</td>\n",
       "      <td>1.273991</td>\n",
       "      <td>-0.069985</td>\n",
       "      <td>-0.949091</td>\n",
       "      <td>1.504873</td>\n",
       "      <td>1.536638</td>\n",
       "      <td>1.026819</td>\n",
       "      <td>-2.021322</td>\n",
       "      <td>1.291818</td>\n",
       "      <td>146.943920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>-0.612028</td>\n",
       "      <td>1.702648</td>\n",
       "      <td>0.873366</td>\n",
       "      <td>0.224716</td>\n",
       "      <td>-0.406032</td>\n",
       "      <td>-1.473677</td>\n",
       "      <td>1.725432</td>\n",
       "      <td>1.325353</td>\n",
       "      <td>-0.119919</td>\n",
       "      <td>0.893863</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.245460</td>\n",
       "      <td>-2.305707</td>\n",
       "      <td>-0.761352</td>\n",
       "      <td>0.269793</td>\n",
       "      <td>1.498866</td>\n",
       "      <td>1.421475</td>\n",
       "      <td>-2.102509</td>\n",
       "      <td>-0.045771</td>\n",
       "      <td>0.983663</td>\n",
       "      <td>-192.974407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X1        X2        X3        X4        X5        X6        X7  \\\n",
       "677   0.731869 -1.096852  0.198551  1.108424 -0.600812  0.722716 -0.332837   \n",
       "888   1.041167 -1.356877  1.170723 -0.192536 -0.010444 -1.059061 -0.552038   \n",
       "743  -0.142184  0.677312  1.673367 -1.631981  0.896933 -0.736006  0.955523   \n",
       "178   0.515979  0.258770 -0.232026 -0.110359 -0.821613  1.278475 -0.550324   \n",
       "1325 -0.612028  1.702648  0.873366  0.224716 -0.406032 -1.473677  1.725432   \n",
       "\n",
       "            X8        X9       X10  ...      X192      X193      X194  \\\n",
       "677  -0.436027 -0.812805 -0.391231  ...  0.109321 -0.827960  0.030530   \n",
       "888  -0.556104  1.435185 -0.376649  ...  0.610066 -0.499520 -1.536939   \n",
       "743   0.473728  0.399525  2.004731  ...  0.172301  0.444955  0.052372   \n",
       "178   0.700158  1.495035 -0.447937  ... -1.255225  1.273991 -0.069985   \n",
       "1325  1.325353 -0.119919  0.893863  ... -1.245460 -2.305707 -0.761352   \n",
       "\n",
       "          X195      X196      X197      X198      X199      X200           y  \n",
       "677  -0.268029  1.521622  0.364885  0.558242  0.860434  0.513657 -142.554141  \n",
       "888  -1.110738  0.663073 -1.174878  0.016668  0.144020  0.429925  230.218687  \n",
       "743   0.567104 -0.477640  1.033732 -0.714290 -0.787753 -1.367362  -66.363159  \n",
       "178  -0.949091  1.504873  1.536638  1.026819 -2.021322  1.291818  146.943920  \n",
       "1325  0.269793  1.498866  1.421475 -2.102509 -0.045771  0.983663 -192.974407  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1404   -201.137022\n",
       "927      41.557819\n",
       "936    -101.220993\n",
       "451     364.910117\n",
       "317      73.397303\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['y']\n",
    "y.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X191</th>\n",
       "      <th>X192</th>\n",
       "      <th>X193</th>\n",
       "      <th>X194</th>\n",
       "      <th>X195</th>\n",
       "      <th>X196</th>\n",
       "      <th>X197</th>\n",
       "      <th>X198</th>\n",
       "      <th>X199</th>\n",
       "      <th>X200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>-1.110527</td>\n",
       "      <td>-2.043829</td>\n",
       "      <td>-0.731589</td>\n",
       "      <td>0.873199</td>\n",
       "      <td>-1.433032</td>\n",
       "      <td>0.102718</td>\n",
       "      <td>-0.261570</td>\n",
       "      <td>-0.409058</td>\n",
       "      <td>1.133024</td>\n",
       "      <td>0.954732</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.327056</td>\n",
       "      <td>0.193464</td>\n",
       "      <td>0.565812</td>\n",
       "      <td>-1.355431</td>\n",
       "      <td>1.186120</td>\n",
       "      <td>0.691204</td>\n",
       "      <td>-0.830774</td>\n",
       "      <td>-0.106530</td>\n",
       "      <td>-1.206052</td>\n",
       "      <td>2.252094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>0.235448</td>\n",
       "      <td>2.019877</td>\n",
       "      <td>-0.735402</td>\n",
       "      <td>1.078222</td>\n",
       "      <td>-1.940690</td>\n",
       "      <td>-0.488953</td>\n",
       "      <td>1.036840</td>\n",
       "      <td>-0.533786</td>\n",
       "      <td>0.189202</td>\n",
       "      <td>0.053152</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.848562</td>\n",
       "      <td>-0.276505</td>\n",
       "      <td>1.001327</td>\n",
       "      <td>-0.068792</td>\n",
       "      <td>-0.952933</td>\n",
       "      <td>-1.563621</td>\n",
       "      <td>1.296935</td>\n",
       "      <td>1.287299</td>\n",
       "      <td>0.135743</td>\n",
       "      <td>-0.299573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>1.410450</td>\n",
       "      <td>1.528265</td>\n",
       "      <td>0.796285</td>\n",
       "      <td>-0.154407</td>\n",
       "      <td>1.035801</td>\n",
       "      <td>1.489065</td>\n",
       "      <td>-0.602469</td>\n",
       "      <td>-1.129376</td>\n",
       "      <td>-1.025087</td>\n",
       "      <td>-0.979529</td>\n",
       "      <td>...</td>\n",
       "      <td>1.517820</td>\n",
       "      <td>2.561999</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>-1.138378</td>\n",
       "      <td>-1.488756</td>\n",
       "      <td>0.554540</td>\n",
       "      <td>-0.088691</td>\n",
       "      <td>0.427252</td>\n",
       "      <td>-0.857795</td>\n",
       "      <td>2.036639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>0.245045</td>\n",
       "      <td>-1.028075</td>\n",
       "      <td>-0.320860</td>\n",
       "      <td>-0.589036</td>\n",
       "      <td>1.090711</td>\n",
       "      <td>1.092439</td>\n",
       "      <td>0.528472</td>\n",
       "      <td>0.980878</td>\n",
       "      <td>-1.130850</td>\n",
       "      <td>1.801174</td>\n",
       "      <td>...</td>\n",
       "      <td>1.053027</td>\n",
       "      <td>0.235578</td>\n",
       "      <td>-0.040160</td>\n",
       "      <td>0.284590</td>\n",
       "      <td>1.472368</td>\n",
       "      <td>-0.260753</td>\n",
       "      <td>-0.498578</td>\n",
       "      <td>0.448862</td>\n",
       "      <td>-0.315314</td>\n",
       "      <td>-1.601842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>-0.561531</td>\n",
       "      <td>-0.273908</td>\n",
       "      <td>0.399256</td>\n",
       "      <td>-0.473119</td>\n",
       "      <td>0.380504</td>\n",
       "      <td>1.150283</td>\n",
       "      <td>0.144404</td>\n",
       "      <td>0.492265</td>\n",
       "      <td>-0.163101</td>\n",
       "      <td>-1.365345</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.075239</td>\n",
       "      <td>0.915370</td>\n",
       "      <td>-0.305831</td>\n",
       "      <td>-1.492897</td>\n",
       "      <td>1.281821</td>\n",
       "      <td>-0.153057</td>\n",
       "      <td>0.943402</td>\n",
       "      <td>-0.805119</td>\n",
       "      <td>-0.108138</td>\n",
       "      <td>0.224261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X1        X2        X3        X4        X5        X6        X7  \\\n",
       "851  -1.110527 -2.043829 -0.731589  0.873199 -1.433032  0.102718 -0.261570   \n",
       "1072  0.235448  2.019877 -0.735402  1.078222 -1.940690 -0.488953  1.036840   \n",
       "1402  1.410450  1.528265  0.796285 -0.154407  1.035801  1.489065 -0.602469   \n",
       "790   0.245045 -1.028075 -0.320860 -0.589036  1.090711  1.092439  0.528472   \n",
       "207  -0.561531 -0.273908  0.399256 -0.473119  0.380504  1.150283  0.144404   \n",
       "\n",
       "            X8        X9       X10  ...      X191      X192      X193  \\\n",
       "851  -0.409058  1.133024  0.954732  ... -0.327056  0.193464  0.565812   \n",
       "1072 -0.533786  0.189202  0.053152  ... -1.848562 -0.276505  1.001327   \n",
       "1402 -1.129376 -1.025087 -0.979529  ...  1.517820  2.561999  0.029412   \n",
       "790   0.980878 -1.130850  1.801174  ...  1.053027  0.235578 -0.040160   \n",
       "207   0.492265 -0.163101 -1.365345  ... -2.075239  0.915370 -0.305831   \n",
       "\n",
       "          X194      X195      X196      X197      X198      X199      X200  \n",
       "851  -1.355431  1.186120  0.691204 -0.830774 -0.106530 -1.206052  2.252094  \n",
       "1072 -0.068792 -0.952933 -1.563621  1.296935  1.287299  0.135743 -0.299573  \n",
       "1402 -1.138378 -1.488756  0.554540 -0.088691  0.427252 -0.857795  2.036639  \n",
       "790   0.284590  1.472368 -0.260753 -0.498578  0.448862 -0.315314 -1.601842  \n",
       "207  -1.492897  1.281821 -0.153057  0.943402 -0.805119 -0.108138  0.224261  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data.drop(columns=['y'])\n",
    "x.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test splits\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection using Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.36162195e-03, -2.61905579e-03,  2.62621516e-03,  6.62678597e-03,\n",
       "        1.29668952e-03,  9.12643150e+01,  6.21518077e-03, -7.72436669e-04,\n",
       "        6.59765792e-03, -8.07933354e-04, -3.71842455e-04, -1.50835511e-03,\n",
       "        4.13605592e-04, -1.37028595e-03,  6.50879979e-03, -9.72610295e-04,\n",
       "        2.72102378e+01, -1.46400778e-03, -5.02243593e-04,  1.53171161e-03,\n",
       "        2.31693745e-03, -5.48509976e-03,  2.74349198e-03, -2.50256434e-03,\n",
       "        2.61836051e-03,  1.51146793e-03,  3.51989936e-03,  3.41365093e+00,\n",
       "        1.74428954e-03, -4.38865463e-03,  4.53538602e-03, -7.88059872e-03,\n",
       "       -6.02482316e-04, -1.71154406e-03,  2.56746272e-03, -4.21485958e-03,\n",
       "        2.00064442e-03, -4.58061905e-03, -4.11307331e-03, -3.56022940e-03,\n",
       "        1.23912199e-03, -4.58340027e-03,  7.02367826e-03,  8.65671482e-04,\n",
       "       -1.04630980e-03,  3.71063477e-03,  4.56488538e-03,  3.99541609e-04,\n",
       "        5.21006034e-03,  9.77879712e-04, -5.22726142e-03,  8.98105648e+01,\n",
       "       -3.36162978e-03,  1.50590012e-03, -9.93018665e-05, -4.81835473e-03,\n",
       "        7.07037654e-03,  2.94001873e-03,  1.28890437e-03, -3.30684389e-04,\n",
       "       -6.29634479e-04,  2.33829148e-03, -8.62049330e-03, -1.07352960e-03,\n",
       "        2.11137956e-03, -5.50816523e-03,  7.34662108e-04,  3.01886857e-03,\n",
       "       -9.30552760e-04, -4.43096664e-03,  1.67607891e-03, -5.51366536e-04,\n",
       "       -1.05186297e-03,  1.19172537e-03,  1.36751256e-03, -5.99177237e-04,\n",
       "        2.67853537e-03,  9.11946190e-04, -2.70251358e-03, -1.31912738e-03,\n",
       "        9.51309798e-04, -6.99819074e-05,  6.87102139e-04, -2.44807480e-03,\n",
       "       -2.15679009e-03,  1.56085459e-03, -2.63354579e-03,  6.06946437e-03,\n",
       "       -8.00457608e-03,  1.70717631e-03,  3.62825011e+01,  6.87711371e-04,\n",
       "       -2.34720324e-03,  5.80453456e-03,  5.59915077e-03,  1.69853874e-03,\n",
       "        4.50890180e-04, -7.25755346e-04, -5.46342590e-03,  1.56218517e-03,\n",
       "       -5.96809556e-03,  4.47112741e-03, -3.08803958e-03,  5.45836012e-03,\n",
       "       -6.44911408e-03, -2.72826721e-04,  1.03262446e-03,  1.01184822e-02,\n",
       "        2.84859332e-03, -1.15804169e-03, -1.83298891e-03, -8.46729010e-03,\n",
       "        7.70784899e+01,  7.30754209e-04,  2.78873972e-03, -1.28453011e-03,\n",
       "        2.99008288e-03, -5.27568347e-04, -2.68926572e-03,  3.96429958e-03,\n",
       "       -5.70918765e-03, -4.99311883e-03,  1.55429759e-03, -2.86093140e-03,\n",
       "        1.86344083e-04,  1.53969758e-03,  9.33795086e-03,  4.74369465e-03,\n",
       "        1.30025658e-03,  1.01002079e-02,  2.14374630e-03,  2.38584297e-03,\n",
       "       -4.90065973e-03,  2.13250615e-03,  2.13335011e-03,  3.18255837e-03,\n",
       "       -3.79623860e-03, -2.44886834e-03,  7.85945670e-04,  1.79048650e-03,\n",
       "       -1.19086188e-03,  1.80816592e-04, -3.92149602e-03,  6.44365280e+01,\n",
       "       -5.41215544e-03,  4.77591626e-03, -1.68193693e-03, -6.88989223e-03,\n",
       "        6.62166307e-03,  1.24341562e-03, -3.76817635e-03, -4.18086545e-03,\n",
       "        3.35737136e-03, -2.47972090e-03, -4.82628721e-04,  5.52953907e-04,\n",
       "       -2.73298647e-04, -4.23126904e-03, -7.85780228e-04,  3.71423641e-04,\n",
       "        1.41465897e+01,  5.73111721e-03,  1.04374911e-03,  2.09317432e-03,\n",
       "       -3.38915165e-03,  5.96660254e+01,  3.16297087e-03,  4.07192034e-03,\n",
       "       -5.19525196e-03,  8.47341364e-03, -5.44416465e-03, -2.51330036e-03,\n",
       "       -7.53993016e-03,  1.73462065e-03, -6.19685400e-03, -5.27029533e-03,\n",
       "        5.07875987e-03, -3.02670498e-03,  1.97789154e-03, -4.13408277e-03,\n",
       "        5.98745097e+01,  1.32999085e-03,  2.83848115e-03,  1.64330266e-03,\n",
       "        8.84409714e-03,  9.90583594e-04, -2.78997334e-03, -1.05812619e-03,\n",
       "       -6.56028091e-03, -4.06795286e-03,  3.41255375e-03,  1.10592143e-03,\n",
       "        1.21636196e-03, -3.03592005e-03, -1.97437607e-03, -1.65624195e-03,\n",
       "        4.18068830e-03,  5.56555395e-03,  6.55220459e-05,  4.11833458e-04])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(x_train_scaled,y_train)\n",
    "\n",
    "feature_coeffs = lr.coef_\n",
    "feature_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 91.26431500307883),\n",
       " (51, 89.81056482903098),\n",
       " (112, 77.07848993969463),\n",
       " (143, 64.4365280468953),\n",
       " (180, 59.87450966966119),\n",
       " (165, 59.666025427008165),\n",
       " (90, 36.28250105292701),\n",
       " (16, 27.21023784832074),\n",
       " (160, 14.146589745971404),\n",
       " (27, 3.4136509293518316),\n",
       " (107, 0.010118482153932393),\n",
       " (129, 0.010100207875092915),\n",
       " (126, 0.009337950855655919),\n",
       " (184, 0.008844097141829987),\n",
       " (62, -0.008620493295929066),\n",
       " (169, 0.008473413638278693),\n",
       " (111, -0.00846729010036995),\n",
       " (88, -0.00800457608077565),\n",
       " (31, -0.00788059871978497),\n",
       " (172, -0.007539930156088559),\n",
       " (56, 0.007070376541328471),\n",
       " (42, 0.007023678255338339),\n",
       " (147, -0.006889892230146799),\n",
       " (3, 0.0066267859702655585),\n",
       " (148, 0.006621663073719475),\n",
       " (8, 0.006597657917706279),\n",
       " (188, -0.006560280909316596),\n",
       " (14, 0.0065087997879818005),\n",
       " (104, -0.006449114075764262),\n",
       " (0, -0.006361621954950521),\n",
       " (6, 0.006215180771615536),\n",
       " (174, -0.006196853999117735),\n",
       " (87, 0.006069464373945843),\n",
       " (100, -0.005968095557019382),\n",
       " (93, 0.005804534563206065),\n",
       " (161, 0.0057311172138967414),\n",
       " (120, -0.005709187648043679),\n",
       " (94, 0.00559915076591988),\n",
       " (197, 0.005565553947997515),\n",
       " (65, -0.0055081652251498525),\n",
       " (21, -0.0054850997611737284),\n",
       " (98, -0.005463425903539432),\n",
       " (103, 0.005458360119611427),\n",
       " (170, -0.005444164648707783),\n",
       " (144, -0.005412155439216804),\n",
       " (175, -0.005270295332383768),\n",
       " (50, -0.005227261416617779),\n",
       " (48, 0.005210060337333733),\n",
       " (168, -0.005195251961564562),\n",
       " (176, 0.005078759867936711),\n",
       " (121, -0.004993118827643528),\n",
       " (132, -0.0049006597287588605),\n",
       " (55, -0.004818354731131791),\n",
       " (145, 0.004775916260577162),\n",
       " (127, 0.004743694649558483),\n",
       " (41, -0.004583400271870541),\n",
       " (37, -0.0045806190509103395),\n",
       " (46, 0.004564885380817785),\n",
       " (30, 0.004535386018520882),\n",
       " (101, 0.004471127411938447),\n",
       " (69, -0.004430966643988149),\n",
       " (29, -0.0043886546329399145),\n",
       " (157, -0.004231269040701591),\n",
       " (35, -0.004214859581538333),\n",
       " (151, -0.004180865454616267),\n",
       " (196, 0.004180688300812863),\n",
       " (179, -0.004134082772137226),\n",
       " (38, -0.004113073311519777),\n",
       " (167, 0.004071920343635682),\n",
       " (189, -0.0040679528581542),\n",
       " (119, 0.003964299580950126),\n",
       " (142, -0.003921496019922088),\n",
       " (136, -0.00379623859953071),\n",
       " (150, -0.0037681763481351993),\n",
       " (45, 0.003710634768039789),\n",
       " (39, -0.003560229403009707),\n",
       " (26, 0.0035198993588023697),\n",
       " (190, 0.0034125537455174104),\n",
       " (164, -0.0033891516549049427),\n",
       " (52, -0.003361629780083142),\n",
       " (152, 0.0033573713550723028),\n",
       " (135, 0.0031825583651121647),\n",
       " (166, 0.00316297087108941),\n",
       " (102, -0.003088039577869184),\n",
       " (193, -0.0030359200531102637),\n",
       " (177, -0.0030267049838618165),\n",
       " (67, 0.0030188685661922676),\n",
       " (116, 0.0029900828830486947),\n",
       " (57, 0.0029400187339607697),\n",
       " (123, -0.002860931395328059),\n",
       " (108, 0.0028485933249697837),\n",
       " (182, 0.0028384811515032027),\n",
       " (186, -0.002789973340494356),\n",
       " (114, 0.0027887397171202366),\n",
       " (22, 0.0027434919849333994),\n",
       " (78, -0.002702513576503307),\n",
       " (118, -0.0026892657226968986),\n",
       " (76, 0.0026785353747527108),\n",
       " (86, -0.002633545787713132),\n",
       " (2, 0.002626215163654244),\n",
       " (1, -0.002619055794976788),\n",
       " (24, 0.0026183605125176257),\n",
       " (34, 0.0025674627154472773),\n",
       " (171, -0.0025133003608575066),\n",
       " (23, -0.002502564343699998),\n",
       " (153, -0.0024797209036897527),\n",
       " (137, -0.0024488683389716215),\n",
       " (83, -0.002448074803606648),\n",
       " (131, 0.0023858429721268504),\n",
       " (92, -0.0023472032394713516),\n",
       " (61, 0.0023382914771783447),\n",
       " (20, 0.002316937448625822),\n",
       " (84, -0.0021567900895451686),\n",
       " (130, 0.0021437462967490717),\n",
       " (134, 0.002133350110250287),\n",
       " (133, 0.002132506150993585),\n",
       " (64, 0.0021113795564602356),\n",
       " (163, 0.002093174315794144),\n",
       " (36, 0.0020006444207556484),\n",
       " (178, 0.0019778915352777204),\n",
       " (194, -0.001974376066836925),\n",
       " (110, -0.0018329889066568406),\n",
       " (139, 0.0017904864987947633),\n",
       " (28, 0.0017442895423158689),\n",
       " (173, 0.0017346206534885056),\n",
       " (33, -0.0017115440603019116),\n",
       " (89, 0.0017071763120815042),\n",
       " (95, 0.001698538737869626),\n",
       " (146, -0.001681936931742456),\n",
       " (70, 0.0016760789056800007),\n",
       " (195, -0.0016562419520100846),\n",
       " (183, 0.001643302658330903),\n",
       " (99, 0.0015621851660774233),\n",
       " (85, 0.0015608545860681389),\n",
       " (122, 0.001554297594738241),\n",
       " (125, 0.0015396975806578617),\n",
       " (19, 0.0015317116124613506),\n",
       " (25, 0.0015114679338168457),\n",
       " (11, -0.0015083551060790512),\n",
       " (53, 0.0015059001177046838),\n",
       " (17, -0.0014640077763754533),\n",
       " (13, -0.0013702859464164163),\n",
       " (74, 0.00136751255609191),\n",
       " (181, 0.0013299908507785063),\n",
       " (79, -0.0013191273798700553),\n",
       " (128, 0.0013002565762221252),\n",
       " (4, 0.0012966895195170025),\n",
       " (58, 0.0012889043697938973),\n",
       " (115, -0.0012845301127488717),\n",
       " (149, 0.0012434156160942567),\n",
       " (40, 0.0012391219879196447),\n",
       " (192, 0.0012163619593614783),\n",
       " (73, 0.001191725372043706),\n",
       " (140, -0.0011908618834870488),\n",
       " (109, -0.001158041692727707),\n",
       " (191, 0.0011059214324777855),\n",
       " (63, -0.0010735296041799458),\n",
       " (187, -0.0010581261929394348),\n",
       " (72, -0.0010518629661717682),\n",
       " (44, -0.001046309801681744),\n",
       " (162, 0.0010437491098063134),\n",
       " (106, 0.00103262445515373),\n",
       " (185, 0.0009905835936369622),\n",
       " (49, 0.0009778797120094662),\n",
       " (15, -0.000972610294951437),\n",
       " (80, 0.0009513097984985563),\n",
       " (68, -0.0009305527600611541),\n",
       " (77, 0.0009119461900661818),\n",
       " (43, 0.00086567148186667),\n",
       " (9, -0.0008079333540464972),\n",
       " (138, 0.0007859456702599132),\n",
       " (158, -0.0007857802279715997),\n",
       " (7, -0.0007724366685115669),\n",
       " (66, 0.0007346621081557592),\n",
       " (113, 0.0007307542093333286),\n",
       " (97, -0.0007257553460853217),\n",
       " (91, 0.0006877113705154869),\n",
       " (82, 0.0006871021391052778),\n",
       " (60, -0.0006296344786056451),\n",
       " (32, -0.000602482315585462),\n",
       " (75, -0.0005991772365003811),\n",
       " (155, 0.0005529539073096945),\n",
       " (71, -0.0005513665359844211),\n",
       " (117, -0.0005275683465111314),\n",
       " (18, -0.000502243592801932),\n",
       " (154, -0.0004826287205279556),\n",
       " (96, 0.0004508901795698961),\n",
       " (12, 0.0004136055916075243),\n",
       " (199, 0.00041183345774342683),\n",
       " (47, 0.00039954160938826533),\n",
       " (10, -0.00037184245543997463),\n",
       " (159, 0.00037142364101683256),\n",
       " (59, -0.00033068438941752376),\n",
       " (156, -0.00027329864728287134),\n",
       " (105, -0.00027282672133566166),\n",
       " (124, 0.00018634408293394245),\n",
       " (141, 0.00018081659210400503),\n",
       " (54, -9.930186645945582e-05),\n",
       " (81, -6.99819074103658e-05),\n",
       " (198, 6.55220459111483e-05)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_coeffs = sorted(enumerate(feature_coeffs), key=lambda x: abs(x[1]), reverse=True)\n",
    "sorted_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X6', 'X52', 'X113', 'X144', 'X181', 'X166', 'X91', 'X17', 'X161', 'X28']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I chose to use the 10 largest features. \n",
    "selected_features = [x.columns[i] for i, _ in sorted_coeffs[:10]]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Multi-Layer Perceptron Model \n",
    "\n",
    "- ReLu was used as it more computationally efficient and does not suffer from the Vanishing Gradient issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(hidden_layer_sizes=(1000, 1000, 1000))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(hidden_layer_sizes=(1000, 1000, 1000))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=(1000, 1000, 1000))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = MLPRegressor(hidden_layer_sizes=(1000, 1000, 1000), activation='relu')\n",
    "model.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test_scaled)\n",
    "\n",
    "mean = mean_squared_error(y_test,y_pred)\n",
    "r2score = r2_score(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 3184.3672298031506\n",
      "R-squared (R2) Score: 0.9014848996732575\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Squared Error (MSE):\", mean)\n",
    "print(\"R-squared (R2) Score:\", r2score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "strath",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
