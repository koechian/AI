{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task / Question\n",
    "1. Load the given dataset into a pandas data frame.\n",
    "2. Develop a Multi-Layer Perceptron (MLP) model to regress the target variable y.\n",
    "3. Evaluate the model using appropriate metrics.\n",
    "4. Your MLP model should have at least 3 hidden layers and 1 output layer. You can use any number of neurons in each layer however, you should be able to justify your choice.\n",
    "5. You can use any activation function in the hidden layers however, you should be able to justify your choice. Remember this is a regression problem hence referring to the equation *y = mx + c* might help.\n",
    "\n",
    "#### Items to consider:\n",
    "1. Dataset has 200 features and 1 target variable. Not all features are relevant for the target variable hence apply feature selection techniques to select the most relevant features.\n",
    "2. Use appropriate data pre-processing techniques to prepare the data for the model.\n",
    "3. You can use:\n",
    "    - Pytorch\n",
    "    - Tensorflow v2\n",
    "    - Scikit-learn (MLPRegressor)\n",
    "    - Custom implementation of MLP\n",
    "\n",
    "    <br><br>\n",
    "\n",
    "\n",
    "\n",
    "### Deliverables:\n",
    "1. **Jupyter notebook** with the code and results included\n",
    "    - name the notebook using the format: **A-111111.ipynb**, where A is your group and 111111 is your student number. Any other fill names will lead to an automatic 0 mark.\n",
    "    - Do not attempt to submit your file via email. If E-Learning fails on the deadline, an alternative submission method will be provided; to avoid this chaos simply  do your work before the deadline.\n",
    "    - Any slight hint of plagiarism will lead to an automatic 0 mark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X192</th>\n",
       "      <th>X193</th>\n",
       "      <th>X194</th>\n",
       "      <th>X195</th>\n",
       "      <th>X196</th>\n",
       "      <th>X197</th>\n",
       "      <th>X198</th>\n",
       "      <th>X199</th>\n",
       "      <th>X200</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>1.198482</td>\n",
       "      <td>0.421901</td>\n",
       "      <td>-0.057357</td>\n",
       "      <td>-0.812432</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>0.808387</td>\n",
       "      <td>-1.088023</td>\n",
       "      <td>0.467322</td>\n",
       "      <td>1.083326</td>\n",
       "      <td>-0.361963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793922</td>\n",
       "      <td>-0.594955</td>\n",
       "      <td>0.645100</td>\n",
       "      <td>0.215660</td>\n",
       "      <td>-0.614969</td>\n",
       "      <td>-0.598725</td>\n",
       "      <td>1.983430</td>\n",
       "      <td>1.651300</td>\n",
       "      <td>0.635038</td>\n",
       "      <td>264.993304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>-0.790611</td>\n",
       "      <td>1.798816</td>\n",
       "      <td>0.507754</td>\n",
       "      <td>0.153409</td>\n",
       "      <td>0.199356</td>\n",
       "      <td>2.756274</td>\n",
       "      <td>0.274984</td>\n",
       "      <td>0.812156</td>\n",
       "      <td>-0.585318</td>\n",
       "      <td>0.422948</td>\n",
       "      <td>...</td>\n",
       "      <td>1.183591</td>\n",
       "      <td>-0.884588</td>\n",
       "      <td>0.535226</td>\n",
       "      <td>-0.804356</td>\n",
       "      <td>-0.764488</td>\n",
       "      <td>-0.426859</td>\n",
       "      <td>1.824522</td>\n",
       "      <td>0.909793</td>\n",
       "      <td>-1.356508</td>\n",
       "      <td>453.936171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0.239480</td>\n",
       "      <td>0.142194</td>\n",
       "      <td>0.224224</td>\n",
       "      <td>-0.550874</td>\n",
       "      <td>0.333568</td>\n",
       "      <td>0.167627</td>\n",
       "      <td>-0.289393</td>\n",
       "      <td>-0.442021</td>\n",
       "      <td>-0.872856</td>\n",
       "      <td>0.341103</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.862876</td>\n",
       "      <td>0.461606</td>\n",
       "      <td>-1.080555</td>\n",
       "      <td>0.220297</td>\n",
       "      <td>0.458183</td>\n",
       "      <td>-0.282206</td>\n",
       "      <td>-2.458803</td>\n",
       "      <td>1.644938</td>\n",
       "      <td>0.602713</td>\n",
       "      <td>242.356480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.230011</td>\n",
       "      <td>-1.885474</td>\n",
       "      <td>0.372863</td>\n",
       "      <td>0.693736</td>\n",
       "      <td>-0.182096</td>\n",
       "      <td>0.137533</td>\n",
       "      <td>-1.457881</td>\n",
       "      <td>0.927342</td>\n",
       "      <td>0.400780</td>\n",
       "      <td>-1.252192</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.308330</td>\n",
       "      <td>-1.653200</td>\n",
       "      <td>0.248096</td>\n",
       "      <td>-1.041215</td>\n",
       "      <td>-0.309016</td>\n",
       "      <td>2.151667</td>\n",
       "      <td>1.839620</td>\n",
       "      <td>-0.929768</td>\n",
       "      <td>0.280111</td>\n",
       "      <td>-55.494916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>0.614802</td>\n",
       "      <td>-0.135875</td>\n",
       "      <td>-0.620497</td>\n",
       "      <td>0.534948</td>\n",
       "      <td>0.674651</td>\n",
       "      <td>0.390903</td>\n",
       "      <td>0.122188</td>\n",
       "      <td>-0.443522</td>\n",
       "      <td>0.917748</td>\n",
       "      <td>1.231139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287304</td>\n",
       "      <td>1.069283</td>\n",
       "      <td>-2.439970</td>\n",
       "      <td>1.160076</td>\n",
       "      <td>-1.964114</td>\n",
       "      <td>-0.921588</td>\n",
       "      <td>0.011535</td>\n",
       "      <td>-0.393941</td>\n",
       "      <td>1.169200</td>\n",
       "      <td>146.931694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>1.437298</td>\n",
       "      <td>-0.481727</td>\n",
       "      <td>0.688852</td>\n",
       "      <td>-1.654683</td>\n",
       "      <td>0.921132</td>\n",
       "      <td>-0.430467</td>\n",
       "      <td>-3.469917</td>\n",
       "      <td>-0.226978</td>\n",
       "      <td>1.940819</td>\n",
       "      <td>0.058462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.720803</td>\n",
       "      <td>-1.422832</td>\n",
       "      <td>-0.903205</td>\n",
       "      <td>-0.609044</td>\n",
       "      <td>-0.545022</td>\n",
       "      <td>2.371244</td>\n",
       "      <td>1.254854</td>\n",
       "      <td>1.082608</td>\n",
       "      <td>0.248875</td>\n",
       "      <td>-169.736576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>1.221228</td>\n",
       "      <td>-0.001339</td>\n",
       "      <td>-0.458483</td>\n",
       "      <td>-1.649126</td>\n",
       "      <td>-1.230147</td>\n",
       "      <td>0.759465</td>\n",
       "      <td>0.134108</td>\n",
       "      <td>-0.341343</td>\n",
       "      <td>-0.963062</td>\n",
       "      <td>0.056984</td>\n",
       "      <td>...</td>\n",
       "      <td>1.087657</td>\n",
       "      <td>-0.808774</td>\n",
       "      <td>0.246261</td>\n",
       "      <td>-1.403427</td>\n",
       "      <td>-0.526939</td>\n",
       "      <td>-0.181756</td>\n",
       "      <td>0.288818</td>\n",
       "      <td>-0.215641</td>\n",
       "      <td>0.785585</td>\n",
       "      <td>76.400889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>-0.161198</td>\n",
       "      <td>0.185536</td>\n",
       "      <td>-0.478614</td>\n",
       "      <td>0.104053</td>\n",
       "      <td>-1.171813</td>\n",
       "      <td>-0.092432</td>\n",
       "      <td>-1.470237</td>\n",
       "      <td>0.353567</td>\n",
       "      <td>0.606548</td>\n",
       "      <td>0.316637</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.552699</td>\n",
       "      <td>1.021248</td>\n",
       "      <td>0.725523</td>\n",
       "      <td>0.398598</td>\n",
       "      <td>-0.438200</td>\n",
       "      <td>0.932721</td>\n",
       "      <td>-0.019001</td>\n",
       "      <td>0.599213</td>\n",
       "      <td>-0.423478</td>\n",
       "      <td>114.618357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>0.004391</td>\n",
       "      <td>-1.346463</td>\n",
       "      <td>-1.616855</td>\n",
       "      <td>0.096739</td>\n",
       "      <td>0.593328</td>\n",
       "      <td>-1.427080</td>\n",
       "      <td>-0.180624</td>\n",
       "      <td>-0.104666</td>\n",
       "      <td>-0.143237</td>\n",
       "      <td>2.499584</td>\n",
       "      <td>...</td>\n",
       "      <td>1.393088</td>\n",
       "      <td>-0.888725</td>\n",
       "      <td>0.351978</td>\n",
       "      <td>1.114421</td>\n",
       "      <td>1.075549</td>\n",
       "      <td>-1.088599</td>\n",
       "      <td>-0.943326</td>\n",
       "      <td>-2.617266</td>\n",
       "      <td>-0.277799</td>\n",
       "      <td>-164.361068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>-0.896130</td>\n",
       "      <td>1.310159</td>\n",
       "      <td>1.112349</td>\n",
       "      <td>-0.222219</td>\n",
       "      <td>0.364094</td>\n",
       "      <td>-2.029945</td>\n",
       "      <td>0.935192</td>\n",
       "      <td>0.111382</td>\n",
       "      <td>0.594272</td>\n",
       "      <td>0.625218</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.349782</td>\n",
       "      <td>0.234437</td>\n",
       "      <td>-0.090169</td>\n",
       "      <td>0.260827</td>\n",
       "      <td>-0.845195</td>\n",
       "      <td>1.593686</td>\n",
       "      <td>-0.309679</td>\n",
       "      <td>-0.894137</td>\n",
       "      <td>0.477895</td>\n",
       "      <td>-262.052547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X1        X2        X3        X4        X5        X6        X7  \\\n",
       "552   1.198482  0.421901 -0.057357 -0.812432  0.002842  0.808387 -1.088023   \n",
       "832  -0.790611  1.798816  0.507754  0.153409  0.199356  2.756274  0.274984   \n",
       "884   0.239480  0.142194  0.224224 -0.550874  0.333568  0.167627 -0.289393   \n",
       "22    1.230011 -1.885474  0.372863  0.693736 -0.182096  0.137533 -1.457881   \n",
       "435   0.614802 -0.135875 -0.620497  0.534948  0.674651  0.390903  0.122188   \n",
       "1487  1.437298 -0.481727  0.688852 -1.654683  0.921132 -0.430467 -3.469917   \n",
       "732   1.221228 -0.001339 -0.458483 -1.649126 -1.230147  0.759465  0.134108   \n",
       "1347 -0.161198  0.185536 -0.478614  0.104053 -1.171813 -0.092432 -1.470237   \n",
       "1109  0.004391 -1.346463 -1.616855  0.096739  0.593328 -1.427080 -0.180624   \n",
       "522  -0.896130  1.310159  1.112349 -0.222219  0.364094 -2.029945  0.935192   \n",
       "\n",
       "            X8        X9       X10  ...      X192      X193      X194  \\\n",
       "552   0.467322  1.083326 -0.361963  ...  0.793922 -0.594955  0.645100   \n",
       "832   0.812156 -0.585318  0.422948  ...  1.183591 -0.884588  0.535226   \n",
       "884  -0.442021 -0.872856  0.341103  ... -1.862876  0.461606 -1.080555   \n",
       "22    0.927342  0.400780 -1.252192  ... -0.308330 -1.653200  0.248096   \n",
       "435  -0.443522  0.917748  1.231139  ...  0.287304  1.069283 -2.439970   \n",
       "1487 -0.226978  1.940819  0.058462  ...  0.720803 -1.422832 -0.903205   \n",
       "732  -0.341343 -0.963062  0.056984  ...  1.087657 -0.808774  0.246261   \n",
       "1347  0.353567  0.606548  0.316637  ... -1.552699  1.021248  0.725523   \n",
       "1109 -0.104666 -0.143237  2.499584  ...  1.393088 -0.888725  0.351978   \n",
       "522   0.111382  0.594272  0.625218  ... -0.349782  0.234437 -0.090169   \n",
       "\n",
       "          X195      X196      X197      X198      X199      X200           y  \n",
       "552   0.215660 -0.614969 -0.598725  1.983430  1.651300  0.635038  264.993304  \n",
       "832  -0.804356 -0.764488 -0.426859  1.824522  0.909793 -1.356508  453.936171  \n",
       "884   0.220297  0.458183 -0.282206 -2.458803  1.644938  0.602713  242.356480  \n",
       "22   -1.041215 -0.309016  2.151667  1.839620 -0.929768  0.280111  -55.494916  \n",
       "435   1.160076 -1.964114 -0.921588  0.011535 -0.393941  1.169200  146.931694  \n",
       "1487 -0.609044 -0.545022  2.371244  1.254854  1.082608  0.248875 -169.736576  \n",
       "732  -1.403427 -0.526939 -0.181756  0.288818 -0.215641  0.785585   76.400889  \n",
       "1347  0.398598 -0.438200  0.932721 -0.019001  0.599213 -0.423478  114.618357  \n",
       "1109  1.114421  1.075549 -1.088599 -0.943326 -2.617266 -0.277799 -164.361068  \n",
       "522   0.260827 -0.845195  1.593686 -0.309679 -0.894137  0.477895 -262.052547  \n",
       "\n",
       "[10 rows x 201 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X192</th>\n",
       "      <th>X193</th>\n",
       "      <th>X194</th>\n",
       "      <th>X195</th>\n",
       "      <th>X196</th>\n",
       "      <th>X197</th>\n",
       "      <th>X198</th>\n",
       "      <th>X199</th>\n",
       "      <th>X200</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>-0.289301</td>\n",
       "      <td>-1.140028</td>\n",
       "      <td>0.347630</td>\n",
       "      <td>-0.001174</td>\n",
       "      <td>-0.458486</td>\n",
       "      <td>0.322466</td>\n",
       "      <td>-0.268243</td>\n",
       "      <td>-0.286404</td>\n",
       "      <td>0.191765</td>\n",
       "      <td>-1.737272</td>\n",
       "      <td>...</td>\n",
       "      <td>1.882603</td>\n",
       "      <td>-0.894385</td>\n",
       "      <td>-0.342980</td>\n",
       "      <td>-0.538579</td>\n",
       "      <td>-0.035581</td>\n",
       "      <td>1.169177</td>\n",
       "      <td>0.463086</td>\n",
       "      <td>-0.241061</td>\n",
       "      <td>0.478705</td>\n",
       "      <td>194.080942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>-0.616798</td>\n",
       "      <td>-0.235736</td>\n",
       "      <td>1.412722</td>\n",
       "      <td>-0.461596</td>\n",
       "      <td>0.404542</td>\n",
       "      <td>0.074411</td>\n",
       "      <td>-0.114590</td>\n",
       "      <td>-1.487059</td>\n",
       "      <td>-1.363790</td>\n",
       "      <td>-1.518844</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.531533</td>\n",
       "      <td>-1.550000</td>\n",
       "      <td>0.712583</td>\n",
       "      <td>-1.508111</td>\n",
       "      <td>-0.191294</td>\n",
       "      <td>-0.711515</td>\n",
       "      <td>1.752392</td>\n",
       "      <td>0.081233</td>\n",
       "      <td>0.380195</td>\n",
       "      <td>17.945200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>0.975304</td>\n",
       "      <td>0.105875</td>\n",
       "      <td>-0.093141</td>\n",
       "      <td>0.225171</td>\n",
       "      <td>-0.199734</td>\n",
       "      <td>-0.195351</td>\n",
       "      <td>-0.090551</td>\n",
       "      <td>0.443272</td>\n",
       "      <td>0.184787</td>\n",
       "      <td>0.858452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147098</td>\n",
       "      <td>0.726038</td>\n",
       "      <td>0.304127</td>\n",
       "      <td>-0.551583</td>\n",
       "      <td>2.137897</td>\n",
       "      <td>-0.291877</td>\n",
       "      <td>0.961311</td>\n",
       "      <td>-1.252255</td>\n",
       "      <td>-0.620422</td>\n",
       "      <td>364.910117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>0.733106</td>\n",
       "      <td>2.163096</td>\n",
       "      <td>0.943709</td>\n",
       "      <td>-0.329514</td>\n",
       "      <td>-0.033183</td>\n",
       "      <td>-2.415496</td>\n",
       "      <td>1.739502</td>\n",
       "      <td>-0.066849</td>\n",
       "      <td>-2.157229</td>\n",
       "      <td>2.043673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280240</td>\n",
       "      <td>1.231035</td>\n",
       "      <td>1.094091</td>\n",
       "      <td>2.067874</td>\n",
       "      <td>1.290005</td>\n",
       "      <td>-1.137047</td>\n",
       "      <td>-1.176001</td>\n",
       "      <td>-0.161057</td>\n",
       "      <td>1.163689</td>\n",
       "      <td>-252.321270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>-0.689208</td>\n",
       "      <td>-1.698772</td>\n",
       "      <td>-0.817090</td>\n",
       "      <td>-0.088058</td>\n",
       "      <td>-1.679901</td>\n",
       "      <td>-0.831272</td>\n",
       "      <td>-0.388137</td>\n",
       "      <td>1.076688</td>\n",
       "      <td>-0.896236</td>\n",
       "      <td>0.495671</td>\n",
       "      <td>...</td>\n",
       "      <td>1.645653</td>\n",
       "      <td>0.455850</td>\n",
       "      <td>-0.224992</td>\n",
       "      <td>-0.807427</td>\n",
       "      <td>0.799503</td>\n",
       "      <td>-1.931635</td>\n",
       "      <td>-0.224008</td>\n",
       "      <td>0.880623</td>\n",
       "      <td>0.341889</td>\n",
       "      <td>-111.935079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X1        X2        X3        X4        X5        X6        X7  \\\n",
       "1389 -0.289301 -1.140028  0.347630 -0.001174 -0.458486  0.322466 -0.268243   \n",
       "1342 -0.616798 -0.235736  1.412722 -0.461596  0.404542  0.074411 -0.114590   \n",
       "451   0.975304  0.105875 -0.093141  0.225171 -0.199734 -0.195351 -0.090551   \n",
       "356   0.733106  2.163096  0.943709 -0.329514 -0.033183 -2.415496  1.739502   \n",
       "246  -0.689208 -1.698772 -0.817090 -0.088058 -1.679901 -0.831272 -0.388137   \n",
       "\n",
       "            X8        X9       X10  ...      X192      X193      X194  \\\n",
       "1389 -0.286404  0.191765 -1.737272  ...  1.882603 -0.894385 -0.342980   \n",
       "1342 -1.487059 -1.363790 -1.518844  ... -0.531533 -1.550000  0.712583   \n",
       "451   0.443272  0.184787  0.858452  ...  0.147098  0.726038  0.304127   \n",
       "356  -0.066849 -2.157229  2.043673  ...  0.280240  1.231035  1.094091   \n",
       "246   1.076688 -0.896236  0.495671  ...  1.645653  0.455850 -0.224992   \n",
       "\n",
       "          X195      X196      X197      X198      X199      X200           y  \n",
       "1389 -0.538579 -0.035581  1.169177  0.463086 -0.241061  0.478705  194.080942  \n",
       "1342 -1.508111 -0.191294 -0.711515  1.752392  0.081233  0.380195   17.945200  \n",
       "451  -0.551583  2.137897 -0.291877  0.961311 -1.252255 -0.620422  364.910117  \n",
       "356   2.067874  1.290005 -1.137047 -1.176001 -0.161057  1.163689 -252.321270  \n",
       "246  -0.807427  0.799503 -1.931635 -0.224008  0.880623  0.341889 -111.935079  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1361   -221.792346\n",
       "1161    290.731470\n",
       "871     256.927693\n",
       "340     -64.236683\n",
       "739     -68.875636\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['y']\n",
    "y.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X191</th>\n",
       "      <th>X192</th>\n",
       "      <th>X193</th>\n",
       "      <th>X194</th>\n",
       "      <th>X195</th>\n",
       "      <th>X196</th>\n",
       "      <th>X197</th>\n",
       "      <th>X198</th>\n",
       "      <th>X199</th>\n",
       "      <th>X200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>-1.431263</td>\n",
       "      <td>-0.536969</td>\n",
       "      <td>-0.501747</td>\n",
       "      <td>0.305498</td>\n",
       "      <td>0.815045</td>\n",
       "      <td>-0.663575</td>\n",
       "      <td>-0.710457</td>\n",
       "      <td>-0.364703</td>\n",
       "      <td>1.513457</td>\n",
       "      <td>-0.707616</td>\n",
       "      <td>...</td>\n",
       "      <td>1.505872</td>\n",
       "      <td>0.008270</td>\n",
       "      <td>-0.191576</td>\n",
       "      <td>-0.444968</td>\n",
       "      <td>1.846716</td>\n",
       "      <td>2.239031</td>\n",
       "      <td>2.899004</td>\n",
       "      <td>-1.083305</td>\n",
       "      <td>2.788915</td>\n",
       "      <td>-1.163532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0.401925</td>\n",
       "      <td>-0.002621</td>\n",
       "      <td>0.544598</td>\n",
       "      <td>1.728027</td>\n",
       "      <td>0.621519</td>\n",
       "      <td>-0.657992</td>\n",
       "      <td>-0.904062</td>\n",
       "      <td>0.379202</td>\n",
       "      <td>0.084496</td>\n",
       "      <td>0.835067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763544</td>\n",
       "      <td>0.520162</td>\n",
       "      <td>-0.280931</td>\n",
       "      <td>-0.630908</td>\n",
       "      <td>0.309915</td>\n",
       "      <td>1.771510</td>\n",
       "      <td>-0.744908</td>\n",
       "      <td>0.164873</td>\n",
       "      <td>1.105228</td>\n",
       "      <td>-1.094875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>-0.992878</td>\n",
       "      <td>0.829782</td>\n",
       "      <td>0.172035</td>\n",
       "      <td>1.366668</td>\n",
       "      <td>-1.187266</td>\n",
       "      <td>0.216560</td>\n",
       "      <td>-1.246236</td>\n",
       "      <td>-1.486613</td>\n",
       "      <td>-0.417790</td>\n",
       "      <td>1.045471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188173</td>\n",
       "      <td>-1.822095</td>\n",
       "      <td>0.071484</td>\n",
       "      <td>0.348904</td>\n",
       "      <td>0.282944</td>\n",
       "      <td>2.575357</td>\n",
       "      <td>-0.087626</td>\n",
       "      <td>0.305523</td>\n",
       "      <td>0.031095</td>\n",
       "      <td>-1.438955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.242679</td>\n",
       "      <td>-0.717851</td>\n",
       "      <td>-0.323027</td>\n",
       "      <td>-0.955156</td>\n",
       "      <td>0.359084</td>\n",
       "      <td>2.913601</td>\n",
       "      <td>0.846076</td>\n",
       "      <td>1.626375</td>\n",
       "      <td>0.613599</td>\n",
       "      <td>1.300746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309821</td>\n",
       "      <td>-0.402780</td>\n",
       "      <td>-0.507388</td>\n",
       "      <td>0.556702</td>\n",
       "      <td>-0.005537</td>\n",
       "      <td>0.654223</td>\n",
       "      <td>0.208303</td>\n",
       "      <td>0.496540</td>\n",
       "      <td>0.230727</td>\n",
       "      <td>0.538992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>-1.822366</td>\n",
       "      <td>0.109500</td>\n",
       "      <td>0.694077</td>\n",
       "      <td>-0.552474</td>\n",
       "      <td>0.242206</td>\n",
       "      <td>0.418946</td>\n",
       "      <td>-1.702111</td>\n",
       "      <td>0.610749</td>\n",
       "      <td>-1.690544</td>\n",
       "      <td>1.763407</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.842685</td>\n",
       "      <td>-1.378249</td>\n",
       "      <td>-0.307880</td>\n",
       "      <td>0.189425</td>\n",
       "      <td>-0.626897</td>\n",
       "      <td>1.506168</td>\n",
       "      <td>-0.081037</td>\n",
       "      <td>0.117088</td>\n",
       "      <td>-0.257312</td>\n",
       "      <td>0.962271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X1        X2        X3        X4        X5        X6        X7  \\\n",
       "118  -1.431263 -0.536969 -0.501747  0.305498  0.815045 -0.663575 -0.710457   \n",
       "444   0.401925 -0.002621  0.544598  1.728027  0.621519 -0.657992 -0.904062   \n",
       "377  -0.992878  0.829782  0.172035  1.366668 -1.187266  0.216560 -1.246236   \n",
       "889   0.242679 -0.717851 -0.323027 -0.955156  0.359084  2.913601  0.846076   \n",
       "1374 -1.822366  0.109500  0.694077 -0.552474  0.242206  0.418946 -1.702111   \n",
       "\n",
       "            X8        X9       X10  ...      X191      X192      X193  \\\n",
       "118  -0.364703  1.513457 -0.707616  ...  1.505872  0.008270 -0.191576   \n",
       "444   0.379202  0.084496  0.835067  ...  0.763544  0.520162 -0.280931   \n",
       "377  -1.486613 -0.417790  1.045471  ...  0.188173 -1.822095  0.071484   \n",
       "889   1.626375  0.613599  1.300746  ...  0.309821 -0.402780 -0.507388   \n",
       "1374  0.610749 -1.690544  1.763407  ... -1.842685 -1.378249 -0.307880   \n",
       "\n",
       "          X194      X195      X196      X197      X198      X199      X200  \n",
       "118  -0.444968  1.846716  2.239031  2.899004 -1.083305  2.788915 -1.163532  \n",
       "444  -0.630908  0.309915  1.771510 -0.744908  0.164873  1.105228 -1.094875  \n",
       "377   0.348904  0.282944  2.575357 -0.087626  0.305523  0.031095 -1.438955  \n",
       "889   0.556702 -0.005537  0.654223  0.208303  0.496540  0.230727  0.538992  \n",
       "1374  0.189425 -0.626897  1.506168 -0.081037  0.117088 -0.257312  0.962271  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data.drop(columns=['y'])\n",
    "x.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test splits\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection using Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.15782639e-03, -3.48218194e-03, -2.44049383e-04,  3.48866280e-03,\n",
       "       -7.06460552e-04,  8.80710716e+01,  6.20334841e-03,  7.69349873e-04,\n",
       "        2.92707426e-03, -2.89730479e-03,  2.22115082e-03, -3.39477650e-04,\n",
       "       -2.07757312e-03, -1.24352531e-03,  1.55257344e-03, -3.62728399e-03,\n",
       "        2.78169135e+01,  5.06120892e-03, -1.00894935e-03, -1.48597773e-03,\n",
       "        3.99362129e-03, -2.62918462e-03,  9.90355611e-04, -1.66738983e-03,\n",
       "        3.83447133e-03, -4.31962872e-04,  4.91385552e-03,  3.38119289e+00,\n",
       "        2.88537446e-04, -1.32636184e-03,  1.18350719e-03, -5.24110302e-03,\n",
       "        2.19606100e-03, -3.61192496e-04,  1.18905978e-03, -6.57885244e-03,\n",
       "       -2.19019371e-03, -3.31756921e-03, -6.42587875e-03, -2.58682944e-04,\n",
       "        2.82982186e-03, -3.87244424e-03,  4.03631401e-03, -1.54592812e-03,\n",
       "       -2.09946029e-03,  8.37368908e-04,  3.43370702e-03, -1.04145071e-03,\n",
       "        3.60729993e-03,  3.25681442e-03, -4.19313854e-03,  8.91101836e+01,\n",
       "       -2.68955625e-04,  1.78433744e-03, -1.28625647e-03, -4.41244626e-03,\n",
       "        6.28578751e-04,  2.74624763e-03,  5.13852106e-03, -4.30040545e-04,\n",
       "       -4.64851713e-04,  2.18259275e-03, -1.37177060e-02, -2.64674246e-03,\n",
       "        1.08258937e-03, -4.21161116e-04, -2.02531646e-03,  1.22548533e-03,\n",
       "        3.10577550e-03, -4.62205765e-03,  7.64884351e-04, -3.72025650e-03,\n",
       "        4.02762156e-03,  4.16930631e-03,  3.66887592e-03, -1.16966403e-03,\n",
       "        5.42862700e-03, -6.30224184e-04, -7.42241000e-05,  1.60195434e-03,\n",
       "        3.87826706e-03, -2.88034668e-04,  2.50852946e-03, -1.50467920e-03,\n",
       "       -3.54542475e-03,  1.56866983e-03, -2.11316993e-03,  1.20923824e-04,\n",
       "       -4.41037015e-03, -8.19118211e-05,  3.60232104e+01, -1.14299196e-03,\n",
       "        1.31670913e-03,  8.73492234e-03,  5.38423759e-03, -4.21640240e-03,\n",
       "        3.74415236e-03, -1.47703358e-04, -5.44540081e-03,  3.14170920e-04,\n",
       "       -3.46164449e-03, -2.49567654e-03, -2.56283703e-03,  4.53320489e-03,\n",
       "       -2.74338107e-03, -2.16608735e-03,  1.00063940e-03,  7.40966436e-03,\n",
       "        1.76312769e-03,  5.40828844e-04,  1.67396050e-03, -5.51680778e-03,\n",
       "        7.66211136e+01,  5.88274691e-03,  3.53975840e-03,  7.54000321e-04,\n",
       "        1.13857655e-03, -7.96303043e-04, -2.24070667e-03, -1.63682927e-03,\n",
       "       -7.98711498e-04, -7.05553835e-04,  3.71894726e-03, -2.47599810e-03,\n",
       "        6.22668434e-04, -5.22234879e-03,  9.98148021e-03,  6.67101381e-03,\n",
       "        6.74698336e-03,  8.69262555e-03,  4.34137341e-03,  2.87988555e-04,\n",
       "        4.33972733e-04, -3.61184085e-03,  2.60613516e-03, -9.19548666e-04,\n",
       "       -5.14289781e-03, -5.37934006e-03, -2.74847994e-03,  4.19139317e-03,\n",
       "       -5.30075126e-03,  8.60492673e-04, -7.25041021e-03,  6.28006168e+01,\n",
       "       -6.03361332e-03,  4.42785984e-03,  8.62585330e-04, -6.35694838e-03,\n",
       "        3.24836921e-03,  5.06635206e-03, -2.50758485e-03, -2.53588933e-03,\n",
       "        7.35569001e-03, -5.95787917e-03, -6.29433125e-03, -2.90888867e-04,\n",
       "       -1.27979639e-05, -4.22847338e-03, -3.00371749e-03,  1.76644624e-03,\n",
       "        1.37754813e+01,  2.59345153e-03,  9.75723678e-04,  3.37244548e-04,\n",
       "       -2.89492118e-03,  5.86545543e+01,  2.61737922e-03,  8.02625896e-03,\n",
       "       -3.69440882e-03,  7.22395332e-03, -3.81039525e-03,  5.16851222e-03,\n",
       "       -5.80097087e-03,  3.23233419e-03, -4.73062695e-03, -1.82652412e-03,\n",
       "        2.49190824e-03, -1.63515219e-03,  2.22827722e-04, -2.47271943e-03,\n",
       "        6.04867086e+01,  1.66340639e-03,  1.72640359e-03,  6.66686973e-04,\n",
       "        6.64919762e-03,  1.29951346e-03,  4.56762818e-03, -1.90973071e-03,\n",
       "       -5.97023509e-03, -5.31427753e-03,  3.59993540e-03,  7.43083589e-04,\n",
       "        4.19210508e-03, -3.62643593e-04, -1.77969387e-03,  5.75401082e-03,\n",
       "        6.65418489e-03,  2.55567108e-03, -1.55794355e-03,  1.61934634e-04])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "\n",
    "feature_coeffs = lr.coef_\n",
    "feature_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(51, 89.11018356477592),\n",
       " (5, 88.07107162767785),\n",
       " (112, 76.62111358123776),\n",
       " (143, 62.800616834667224),\n",
       " (180, 60.4867086230275),\n",
       " (165, 58.65455428492043),\n",
       " (90, 36.02321044344896),\n",
       " (16, 27.816913506930547),\n",
       " (160, 13.775481282802762),\n",
       " (27, 3.381192890752722),\n",
       " (62, -0.013717706029835686),\n",
       " (126, 0.009981480212875482),\n",
       " (93, 0.008734922341807394),\n",
       " (129, 0.00869262554866368),\n",
       " (167, 0.008026258957482213),\n",
       " (107, 0.0074096643606083035),\n",
       " (152, 0.007355690008184368),\n",
       " (142, -0.007250410209803437),\n",
       " (169, 0.00722395332400394),\n",
       " (128, 0.006746983361852532),\n",
       " (127, 0.006671013809489423),\n",
       " (196, 0.006654184893911452),\n",
       " (184, 0.006649197623886494),\n",
       " (35, -0.0065788524355383515),\n",
       " (38, -0.0064258787477049495),\n",
       " (147, -0.006356948378722027),\n",
       " (154, -0.0062943312521628325),\n",
       " (6, 0.006203348405687592),\n",
       " (144, -0.006033613316359876),\n",
       " (188, -0.005970235094959309),\n",
       " (153, -0.005957879165659374),\n",
       " (113, 0.005882746905444325),\n",
       " (172, -0.005800970865406541),\n",
       " (195, 0.00575401082460214),\n",
       " (111, -0.005516807781263733),\n",
       " (98, -0.005445400813549384),\n",
       " (76, 0.005428626999877895),\n",
       " (94, 0.005384237590792651),\n",
       " (137, -0.005379340056562043),\n",
       " (189, -0.0053142775286821875),\n",
       " (140, -0.005300751258509595),\n",
       " (31, -0.005241103015830362),\n",
       " (125, -0.005222348789471365),\n",
       " (171, 0.005168512224192234),\n",
       " (136, -0.005142897805763269),\n",
       " (58, 0.005138521061339496),\n",
       " (149, 0.00506635206016437),\n",
       " (17, 0.005061208923118343),\n",
       " (26, 0.004913855520645161),\n",
       " (174, -0.004730626951743311),\n",
       " (69, -0.004622057653961065),\n",
       " (186, 0.004567628179979466),\n",
       " (103, 0.004533204892839038),\n",
       " (145, 0.004427859841937831),\n",
       " (55, -0.004412446262214154),\n",
       " (88, -0.004410370148869802),\n",
       " (130, 0.004341373412200866),\n",
       " (157, -0.004228473375175845),\n",
       " (95, -0.004216402397541175),\n",
       " (50, -0.004193138540664165),\n",
       " (192, 0.004192105078503872),\n",
       " (139, 0.004191393170779101),\n",
       " (73, 0.00416930631168122),\n",
       " (42, 0.004036314010131825),\n",
       " (72, 0.004027621555029892),\n",
       " (20, 0.003993621291545679),\n",
       " (80, 0.003878267056689033),\n",
       " (41, -0.003872444236197481),\n",
       " (24, 0.003834471330138811),\n",
       " (170, -0.003810395249495002),\n",
       " (96, 0.0037441523597205872),\n",
       " (71, -0.003720256499825325),\n",
       " (122, 0.0037189472618948116),\n",
       " (168, -0.003694408821672379),\n",
       " (74, 0.003668875922314019),\n",
       " (15, -0.003627283985556673),\n",
       " (133, -0.0036118408539405067),\n",
       " (48, 0.0036072999309220144),\n",
       " (190, 0.0035999354041025278),\n",
       " (84, -0.003545424751745463),\n",
       " (114, 0.00353975839765841),\n",
       " (3, 0.0034886628013506282),\n",
       " (1, -0.003482181937920714),\n",
       " (100, -0.003461644486963067),\n",
       " (46, 0.0034337070164092154),\n",
       " (37, -0.0033175692090186004),\n",
       " (49, 0.0032568144207805183),\n",
       " (148, 0.003248369206325652),\n",
       " (173, 0.0032323341860349686),\n",
       " (0, -0.0031578263931467086),\n",
       " (68, 0.003105775496646146),\n",
       " (158, -0.0030037174928772004),\n",
       " (8, 0.0029270742582898635),\n",
       " (9, -0.0028973047904905513),\n",
       " (164, -0.0028949211813875664),\n",
       " (40, 0.0028298218585405266),\n",
       " (138, -0.002748479938594617),\n",
       " (57, 0.0027462476287833937),\n",
       " (104, -0.0027433810675860926),\n",
       " (63, -0.0026467424580296495),\n",
       " (21, -0.0026291846211670133),\n",
       " (166, 0.0026173792151007458),\n",
       " (134, 0.002606135161790313),\n",
       " (161, 0.0025934515270417124),\n",
       " (102, -0.002562837026124143),\n",
       " (197, 0.0025556710846057484),\n",
       " (151, -0.0025358893294020746),\n",
       " (82, 0.002508529457158737),\n",
       " (150, -0.0025075848528803846),\n",
       " (101, -0.0024956765445534046),\n",
       " (176, 0.0024919082365215672),\n",
       " (123, -0.0024759981033941614),\n",
       " (179, -0.0024727194288254317),\n",
       " (118, -0.002240706665046943),\n",
       " (10, 0.0022211508204108554),\n",
       " (32, 0.0021960610030946626),\n",
       " (36, -0.002190193713908606),\n",
       " (61, 0.0021825927484009355),\n",
       " (105, -0.0021660873472794107),\n",
       " (86, -0.0021131699326013553),\n",
       " (44, -0.0020994602916615257),\n",
       " (12, -0.002077573124918075),\n",
       " (66, -0.0020253164637686893),\n",
       " (187, -0.0019097307144697595),\n",
       " (175, -0.0018265241163102353),\n",
       " (53, 0.0017843374426367298),\n",
       " (194, -0.001779693868832144),\n",
       " (159, 0.0017664462398610525),\n",
       " (108, 0.0017631276892440262),\n",
       " (182, 0.0017264035881316975),\n",
       " (110, 0.0016739604990645418),\n",
       " (23, -0.001667389832647359),\n",
       " (181, 0.0016634063926757037),\n",
       " (119, -0.0016368292735471357),\n",
       " (177, -0.001635152194182865),\n",
       " (79, 0.0016019543445492945),\n",
       " (85, 0.0015686698348680306),\n",
       " (198, -0.001557943551151908),\n",
       " (14, 0.0015525734426127258),\n",
       " (43, -0.0015459281155250082),\n",
       " (83, -0.0015046792023476474),\n",
       " (19, -0.0014859777267233198),\n",
       " (29, -0.001326361840233048),\n",
       " (92, 0.0013167091294479238),\n",
       " (185, 0.0012995134602249436),\n",
       " (54, -0.0012862564684947841),\n",
       " (13, -0.0012435253063003415),\n",
       " (67, 0.0012254853290336598),\n",
       " (34, 0.0011890597755375154),\n",
       " (30, 0.0011835071903272265),\n",
       " (75, -0.0011696640292830907),\n",
       " (91, -0.0011429919625864926),\n",
       " (116, 0.0011385765543163728),\n",
       " (64, 0.0010825893662840258),\n",
       " (47, -0.0010414507073281953),\n",
       " (18, -0.0010089493508864678),\n",
       " (106, 0.0010006393993169382),\n",
       " (22, 0.0009903556112647038),\n",
       " (162, 0.0009757236778531464),\n",
       " (135, -0.0009195486659585583),\n",
       " (146, 0.0008625853295456398),\n",
       " (141, 0.0008604926729836038),\n",
       " (45, 0.0008373689079269608),\n",
       " (120, -0.0007987114984757682),\n",
       " (117, -0.0007963030426481055),\n",
       " (7, 0.0007693498725185322),\n",
       " (70, 0.0007648843505885239),\n",
       " (115, 0.0007540003213080126),\n",
       " (191, 0.0007430835893909027),\n",
       " (4, -0.0007064605523297018),\n",
       " (121, -0.0007055538345757117),\n",
       " (183, 0.0006666869734770486),\n",
       " (77, -0.0006302241838742617),\n",
       " (56, 0.0006285787507422924),\n",
       " (124, 0.0006226684342456323),\n",
       " (109, 0.0005408288441773879),\n",
       " (60, -0.0004648517130068086),\n",
       " (132, 0.0004339727325124443),\n",
       " (25, -0.00043196287153735025),\n",
       " (59, -0.0004300405454973344),\n",
       " (65, -0.00042116111614942664),\n",
       " (193, -0.00036264359261650725),\n",
       " (33, -0.0003611924964923574),\n",
       " (11, -0.0003394776498257812),\n",
       " (163, 0.00033724454835937223),\n",
       " (99, 0.0003141709200074061),\n",
       " (155, -0.00029088886694506044),\n",
       " (28, 0.00028853744607637566),\n",
       " (81, -0.0002880346678757473),\n",
       " (131, 0.0002879885547162342),\n",
       " (52, -0.0002689556249393932),\n",
       " (39, -0.00025868294366837574),\n",
       " (2, -0.00024404938294075862),\n",
       " (178, 0.00022282772161208442),\n",
       " (199, 0.000161934633908567),\n",
       " (97, -0.00014770335792668732),\n",
       " (87, 0.00012092382427209003),\n",
       " (89, -8.191182111766393e-05),\n",
       " (78, -7.422409996582502e-05),\n",
       " (156, -1.2797963881816532e-05)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_coeffs = sorted(enumerate(feature_coeffs), key=lambda x: abs(x[1]), reverse=True)\n",
    "sorted_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X52', 'X6', 'X113', 'X144', 'X181', 'X166', 'X91', 'X17', 'X161', 'X28']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I chose to use the 10 largest features. \n",
    "selected_features = [x.columns[i] for i, _ in sorted_coeffs[:10]]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X52</th>\n",
       "      <th>X6</th>\n",
       "      <th>X113</th>\n",
       "      <th>X144</th>\n",
       "      <th>X181</th>\n",
       "      <th>X166</th>\n",
       "      <th>X91</th>\n",
       "      <th>X17</th>\n",
       "      <th>X161</th>\n",
       "      <th>X28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>-1.471343</td>\n",
       "      <td>-0.956339</td>\n",
       "      <td>-0.722024</td>\n",
       "      <td>0.034262</td>\n",
       "      <td>-1.201379</td>\n",
       "      <td>-0.832211</td>\n",
       "      <td>0.087529</td>\n",
       "      <td>1.011444</td>\n",
       "      <td>0.040078</td>\n",
       "      <td>2.097175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1.397100</td>\n",
       "      <td>2.186454</td>\n",
       "      <td>-0.347654</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>-1.147956</td>\n",
       "      <td>0.833797</td>\n",
       "      <td>0.165474</td>\n",
       "      <td>0.547276</td>\n",
       "      <td>1.008831</td>\n",
       "      <td>0.006714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>2.010647</td>\n",
       "      <td>0.561278</td>\n",
       "      <td>0.656782</td>\n",
       "      <td>0.540725</td>\n",
       "      <td>-0.251827</td>\n",
       "      <td>-0.958581</td>\n",
       "      <td>-0.628236</td>\n",
       "      <td>-0.697704</td>\n",
       "      <td>0.791645</td>\n",
       "      <td>0.955113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>0.445199</td>\n",
       "      <td>3.006767</td>\n",
       "      <td>-1.212275</td>\n",
       "      <td>0.037149</td>\n",
       "      <td>-0.032186</td>\n",
       "      <td>0.273216</td>\n",
       "      <td>-0.257512</td>\n",
       "      <td>0.775600</td>\n",
       "      <td>2.000401</td>\n",
       "      <td>-1.585383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0.503396</td>\n",
       "      <td>-0.358197</td>\n",
       "      <td>0.678470</td>\n",
       "      <td>1.487509</td>\n",
       "      <td>2.145514</td>\n",
       "      <td>0.587276</td>\n",
       "      <td>1.794287</td>\n",
       "      <td>-1.494226</td>\n",
       "      <td>1.086311</td>\n",
       "      <td>0.827131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>-1.167801</td>\n",
       "      <td>1.488914</td>\n",
       "      <td>-0.410370</td>\n",
       "      <td>0.974631</td>\n",
       "      <td>-0.886858</td>\n",
       "      <td>-0.465955</td>\n",
       "      <td>0.153882</td>\n",
       "      <td>0.972987</td>\n",
       "      <td>1.605012</td>\n",
       "      <td>0.417313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>0.026394</td>\n",
       "      <td>-0.044161</td>\n",
       "      <td>-1.333040</td>\n",
       "      <td>0.809876</td>\n",
       "      <td>0.547587</td>\n",
       "      <td>0.325260</td>\n",
       "      <td>-0.699058</td>\n",
       "      <td>0.461897</td>\n",
       "      <td>-0.455463</td>\n",
       "      <td>-1.245215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>-0.832220</td>\n",
       "      <td>1.026255</td>\n",
       "      <td>-0.110402</td>\n",
       "      <td>1.134146</td>\n",
       "      <td>-0.160426</td>\n",
       "      <td>-0.226810</td>\n",
       "      <td>-0.206112</td>\n",
       "      <td>-0.600732</td>\n",
       "      <td>-1.931564</td>\n",
       "      <td>0.969964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.801304</td>\n",
       "      <td>-0.253788</td>\n",
       "      <td>-0.001085</td>\n",
       "      <td>0.450219</td>\n",
       "      <td>-0.520041</td>\n",
       "      <td>-1.109464</td>\n",
       "      <td>-0.180564</td>\n",
       "      <td>0.565221</td>\n",
       "      <td>-2.210585</td>\n",
       "      <td>-0.512045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.328279</td>\n",
       "      <td>-1.174165</td>\n",
       "      <td>1.272636</td>\n",
       "      <td>-0.427566</td>\n",
       "      <td>2.049363</td>\n",
       "      <td>0.156537</td>\n",
       "      <td>0.867779</td>\n",
       "      <td>-0.735136</td>\n",
       "      <td>2.236855</td>\n",
       "      <td>0.569347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           X52        X6      X113      X144      X181      X166       X91  \\\n",
       "474  -1.471343 -0.956339 -0.722024  0.034262 -1.201379 -0.832211  0.087529   \n",
       "121   1.397100  2.186454 -0.347654  0.003133 -1.147956  0.833797  0.165474   \n",
       "345   2.010647  0.561278  0.656782  0.540725 -0.251827 -0.958581 -0.628236   \n",
       "420   0.445199  3.006767 -1.212275  0.037149 -0.032186  0.273216 -0.257512   \n",
       "393   0.503396 -0.358197  0.678470  1.487509  2.145514  0.587276  1.794287   \n",
       "1084 -1.167801  1.488914 -0.410370  0.974631 -0.886858 -0.465955  0.153882   \n",
       "903   0.026394 -0.044161 -1.333040  0.809876  0.547587  0.325260 -0.699058   \n",
       "1082 -0.832220  1.026255 -0.110402  1.134146 -0.160426 -0.226810 -0.206112   \n",
       "6    -0.801304 -0.253788 -0.001085  0.450219 -0.520041 -1.109464 -0.180564   \n",
       "13    0.328279 -1.174165  1.272636 -0.427566  2.049363  0.156537  0.867779   \n",
       "\n",
       "           X17      X161       X28  \n",
       "474   1.011444  0.040078  2.097175  \n",
       "121   0.547276  1.008831  0.006714  \n",
       "345  -0.697704  0.791645  0.955113  \n",
       "420   0.775600  2.000401 -1.585383  \n",
       "393  -1.494226  1.086311  0.827131  \n",
       "1084  0.972987  1.605012  0.417313  \n",
       "903   0.461897 -0.455463 -1.245215  \n",
       "1082 -0.600732 -1.931564  0.969964  \n",
       "6     0.565221 -2.210585 -0.512045  \n",
       "13   -0.735136  2.236855  0.569347  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.DataFrame()\n",
    "x_testSelected = pd.DataFrame()\n",
    "y_testSelected = pd.DataFrame()\n",
    "y_trainSelected = pd.DataFrame()\n",
    "\n",
    "for x in selected_features:\n",
    "    features[x] = x_train[x]\n",
    "    x_testSelected[x] = x_test[x]\n",
    "\n",
    "\n",
    "# features.sample(10)\n",
    "x_testSelected.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Multi-Layer Perceptron Model \n",
    "\n",
    "- ReLu was used as it more computationally efficient and does not suffer from the Vanishing Gradient issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(hidden_layer_sizes=(1000, 1000, 1000))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(hidden_layer_sizes=(1000, 1000, 1000))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=(1000, 1000, 1000))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = MLPRegressor(hidden_layer_sizes=(1000, 1000, 1000), activation='relu')\n",
    "model.fit(features, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_testSelected)\n",
    "\n",
    "mean = mean_squared_error(y_test,y_pred)\n",
    "r2score = r2_score(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 13.495221266365379\n",
      "R-squared (R2) Score: 0.9996404770816795\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Squared Error (MSE):\", mean)\n",
    "print(\"R-squared (R2) Score:\", r2score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "strath",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
